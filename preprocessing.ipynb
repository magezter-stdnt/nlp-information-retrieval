{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- akan melakukan preprocessing corpus hasil scraping website halodoc menggunakan stopwords indonesia dan stemming dengan sastrawi\n",
    "- untuk fine-tuning model indoBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# load stopwords\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "\n",
    "# load stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9979, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>title_count</th>\n",
       "      <th>content</th>\n",
       "      <th>content_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.halodoc.com/ibu-perhatikan-5-hal-i...</td>\n",
       "      <td>Ibu, Perhatikan 5 Hal Ini saat Memilih Car Se...</td>\n",
       "      <td>10</td>\n",
       "      <td>Bagi orang tua yang memiliki kendaraan, memili...</td>\n",
       "      <td>540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.halodoc.com/catat-ini-6-tips-menyi...</td>\n",
       "      <td>Catat, Ini 6 Tips Menyimpan Beras agar Tidak ...</td>\n",
       "      <td>9</td>\n",
       "      <td>Sebagai makanan pokok beras harus disimpan den...</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.halodoc.com/waspada-ini-6-bahaya-a...</td>\n",
       "      <td>Waspada, Ini 6 Bahaya Asap Rokok bagi Kesehat...</td>\n",
       "      <td>9</td>\n",
       "      <td>Merokok tidak hanya berbahaya untuk dirimu sen...</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.halodoc.com/sering-terkena-polusi-...</td>\n",
       "      <td>Sering Terkena Polusi, Ketahui Berbagi Cara B...</td>\n",
       "      <td>8</td>\n",
       "      <td>Sehari-hari, manusia terpapar polusi dalam jum...</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.halodoc.com/ini-risiko-dan-manfaat...</td>\n",
       "      <td>Ini Risiko dan Manfaat Implan Payudara yang P...</td>\n",
       "      <td>9</td>\n",
       "      <td>Implan payudara adalah prosedur bedah kosmetik...</td>\n",
       "      <td>547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.halodoc.com/ibu-perhatikan-5-hal-i...   \n",
       "1  https://www.halodoc.com/catat-ini-6-tips-menyi...   \n",
       "2  https://www.halodoc.com/waspada-ini-6-bahaya-a...   \n",
       "3  https://www.halodoc.com/sering-terkena-polusi-...   \n",
       "4  https://www.halodoc.com/ini-risiko-dan-manfaat...   \n",
       "\n",
       "                                               title  title_count  \\\n",
       "0   Ibu, Perhatikan 5 Hal Ini saat Memilih Car Se...           10   \n",
       "1   Catat, Ini 6 Tips Menyimpan Beras agar Tidak ...            9   \n",
       "2   Waspada, Ini 6 Bahaya Asap Rokok bagi Kesehat...            9   \n",
       "3   Sering Terkena Polusi, Ketahui Berbagi Cara B...            8   \n",
       "4   Ini Risiko dan Manfaat Implan Payudara yang P...            9   \n",
       "\n",
       "                                             content  content_count  \n",
       "0  Bagi orang tua yang memiliki kendaraan, memili...            540  \n",
       "1  Sebagai makanan pokok beras harus disimpan den...            564  \n",
       "2  Merokok tidak hanya berbahaya untuk dirimu sen...            649  \n",
       "3  Sehari-hari, manusia terpapar polusi dalam jum...            523  \n",
       "4  Implan payudara adalah prosedur bedah kosmetik...            547  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('scraping/halodocnew_1.csv')\n",
    "print(df.shape)\n",
    "\n",
    "# check dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url              0\n",
       "title            0\n",
       "title_count      0\n",
       "content          0\n",
       "content_count    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>title_count</th>\n",
       "      <th>content</th>\n",
       "      <th>content_count</th>\n",
       "      <th>title_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.halodoc.com/ibu-perhatikan-5-hal-i...</td>\n",
       "      <td>Ibu, Perhatikan 5 Hal Ini saat Memilih Car Se...</td>\n",
       "      <td>10</td>\n",
       "      <td>Bagi orang tua yang memiliki kendaraan, memili...</td>\n",
       "      <td>540</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.halodoc.com/catat-ini-6-tips-menyi...</td>\n",
       "      <td>Catat, Ini 6 Tips Menyimpan Beras agar Tidak ...</td>\n",
       "      <td>9</td>\n",
       "      <td>Sebagai makanan pokok beras harus disimpan den...</td>\n",
       "      <td>564</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.halodoc.com/waspada-ini-6-bahaya-a...</td>\n",
       "      <td>Waspada, Ini 6 Bahaya Asap Rokok bagi Kesehat...</td>\n",
       "      <td>9</td>\n",
       "      <td>Merokok tidak hanya berbahaya untuk dirimu sen...</td>\n",
       "      <td>649</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.halodoc.com/sering-terkena-polusi-...</td>\n",
       "      <td>Sering Terkena Polusi, Ketahui Berbagi Cara B...</td>\n",
       "      <td>8</td>\n",
       "      <td>Sehari-hari, manusia terpapar polusi dalam jum...</td>\n",
       "      <td>523</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.halodoc.com/ini-risiko-dan-manfaat...</td>\n",
       "      <td>Ini Risiko dan Manfaat Implan Payudara yang P...</td>\n",
       "      <td>9</td>\n",
       "      <td>Implan payudara adalah prosedur bedah kosmetik...</td>\n",
       "      <td>547</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.halodoc.com/ibu-perhatikan-5-hal-i...   \n",
       "1  https://www.halodoc.com/catat-ini-6-tips-menyi...   \n",
       "2  https://www.halodoc.com/waspada-ini-6-bahaya-a...   \n",
       "3  https://www.halodoc.com/sering-terkena-polusi-...   \n",
       "4  https://www.halodoc.com/ini-risiko-dan-manfaat...   \n",
       "\n",
       "                                               title  title_count  \\\n",
       "0   Ibu, Perhatikan 5 Hal Ini saat Memilih Car Se...           10   \n",
       "1   Catat, Ini 6 Tips Menyimpan Beras agar Tidak ...            9   \n",
       "2   Waspada, Ini 6 Bahaya Asap Rokok bagi Kesehat...            9   \n",
       "3   Sering Terkena Polusi, Ketahui Berbagi Cara B...            8   \n",
       "4   Ini Risiko dan Manfaat Implan Payudara yang P...            9   \n",
       "\n",
       "                                             content  content_count  \\\n",
       "0  Bagi orang tua yang memiliki kendaraan, memili...            540   \n",
       "1  Sebagai makanan pokok beras harus disimpan den...            564   \n",
       "2  Merokok tidak hanya berbahaya untuk dirimu sen...            649   \n",
       "3  Sehari-hari, manusia terpapar polusi dalam jum...            523   \n",
       "4  Implan payudara adalah prosedur bedah kosmetik...            547   \n",
       "\n",
       "   title_length  \n",
       "0            10  \n",
       "1             9  \n",
       "2             9  \n",
       "3             8  \n",
       "4             9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reassign 'title_length' and 'content_length' in df dengan panjang dari 'title' dan 'content' yang baru (word count)\n",
    "df['title_length'] = df['title'].apply(lambda x: len(x.split()))\n",
    "df['content_count'] = df['content'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Ukuran dataset sebelum preprocessing: (9979, 6)\n",
      "Ukuran dataset setelah preprocessing: (9974, 6)\n"
     ]
    }
   ],
   "source": [
    "# check duplicates\n",
    "print(df.duplicated().sum())\n",
    "print(f\"Ukuran dataset sebelum preprocessing: {df.shape}\")\n",
    "\n",
    "# drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Ukuran dataset setelah preprocessing: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save to csv\n",
    "# df.to_csv('halodocnew_1_preprocessed.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary string in 'content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Removal, Stemming, etc. (probably wont be used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove numbers that are not attached to words\n",
    "# def remove_numbers(text):\n",
    "#     text = re.sub(r'(?<!\\S)\\d+(?!\\S)', '', text)\n",
    "#     return text\n",
    "\n",
    "# df['title'] = df['title'].apply(remove_numbers)\n",
    "# df['content'] = df['content'].apply(remove_numbers)\n",
    "# print('hapus angka beridiri sendiri selesai')\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove punctuation\n",
    "# def remove_punctuation(text):\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)\n",
    "#     return text\n",
    "\n",
    "# df['title'] = df['title'].apply(remove_punctuation)\n",
    "# df['content'] = df['content'].apply(remove_punctuation)\n",
    "# print('hapus tanda baca selesai')\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# # remove numbers\n",
    "# def remove_numbers(text):\n",
    "#     text = re.sub(r'\\d+', '', text)\n",
    "#     return text\n",
    "\n",
    "# df['title'] = df['title'].apply(remove_numbers)\n",
    "# df['content'] = df['content'].apply(remove_numbers)\n",
    "# print('hapus angka selesai')\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# # stopword removal + lowercasing\n",
    "# def remove_stopwords(text):\n",
    "#     text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
    "#     return \" \".join(text)\n",
    "\n",
    "# df['title'] = df['title'].apply(remove_stopwords)\n",
    "# df['content'] = df['content'].apply(remove_stopwords)\n",
    "# print('stopword removal dan lowercase selesai')\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# # stemming\n",
    "# def stemming(text):\n",
    "#     text = [stemmer.stem(word) for word in text.split()]\n",
    "#     return \" \".join(text)\n",
    "\n",
    "# df['title'] = df['title'].apply(stemming)\n",
    "# df['content'] = df['content'].apply(stemming)\n",
    "# print('stemming selesai')\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use Sentence-BERT to get sentence embeddings (feature extraction)\n",
    "\n",
    "# # import library\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# # load model SBERT (pretrained)\n",
    "# model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "# # get sentence embeddings\n",
    "# title_embeddings = model.encode(df['title'].values)\n",
    "# content_embeddings = model.encode(df['content'].values)\n",
    "\n",
    "# # check shape\n",
    "# print(title_embeddings.shape)\n",
    "# print(content_embeddings.shape)\n",
    "\n",
    "# # check embeddings\n",
    "# print(title_embeddings)\n",
    "# print(content_embeddings)\n",
    "\n",
    "# # check shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save embeddings\n",
    "# np.save('title_embeddings.npy', title_embeddings)\n",
    "# np.save('content_embeddings.npy', content_embeddings)\n",
    "\n",
    "# # load embeddings\n",
    "# title_embeddings = np.load('title_embeddings.npy')\n",
    "# content_embeddings = np.load('content_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use content and title embeddings as dataset for transfer learning indoBERT (information retrieval)\n",
    "\n",
    "# # create new dataframe\n",
    "# df_new = pd.DataFrame()\n",
    "\n",
    "# # add title and content embeddings to df_new\n",
    "# df_new['title_embeddings'] = title_embeddings.tolist()\n",
    "# df_new['content_embeddings'] = content_embeddings.tolist()\n",
    "\n",
    "# # add title and content to df_new\n",
    "# df_new['title'] = df['title']\n",
    "# df_new['content'] = df['content']\n",
    "\n",
    "# # add title_length and content_length to df_new\n",
    "# df_new['title_length'] = df['title_length']\n",
    "# df_new['content_length'] = df['content_count']\n",
    "\n",
    "# # check df_new\n",
    "# df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fine-tuning indoBERT (information retrieval)\n",
    "\n",
    "# # import library\n",
    "# import torch\n",
    "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# # check device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load dataset\n",
    "# title_embeddings = torch.tensor(np.array(df_new['title_embeddings'].values.tolist()))\n",
    "# content_embeddings = torch.tensor(np.array(df_new['content_embeddings'].values.tolist()))\n",
    "# title_length = torch.tensor(df_new['title_length'].values)\n",
    "# content_length = torch.tensor(df_new['content_length'].values)\n",
    "\n",
    "# # create TensorDataset\n",
    "# dataset = TensorDataset(title_embeddings, content_embeddings, title_length, content_length)\n",
    "# dataset.tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create DataLoader\n",
    "# dataloader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "# # check dataloader\n",
    "# next(iter(dataloader))\n",
    "\n",
    "# # import library for information retrieval\n",
    "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# # load model\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     'indobenchmark/indobert-base-p1',\n",
    "#     num_labels = 2,\n",
    "#     output_attentions = False,\n",
    "#     output_hidden_states = False\n",
    "# )\n",
    "\n",
    "# # check model\n",
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check model parameters\n",
    "# params = list(model.named_parameters())\n",
    "# print(f'Model BERT memiliki sebanyak {len(params)} parameter yang berbeda.\\n')\n",
    "\n",
    "# print('==== Embedding Layer ====\\n')\n",
    "# for p in params[0:5]:\n",
    "#     print(f'{p[0]} memiliki ukuran {tuple(p[1].size())} dan requires_grad={p[1].requires_grad}')\n",
    "\n",
    "# print('\\n==== First Transformer ====\\n')\n",
    "# for p in params[5:21]: \n",
    "#     print(f'{p[0]} memiliki ukuran {tuple(p[1].size())} dan requires_grad={p[1].requires_grad}')\n",
    "\n",
    "# print('\\n==== Output Layer ====\\n')\n",
    "# for p in params[-4:]:\n",
    "#     print(f'{p[0]} memiliki ukuran {tuple(p[1].size())} dan requires_grad={p[1].requires_grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tokenization df to list\n",
    "# title = df['title'].tolist()\n",
    "# content = df['content'].tolist()\n",
    "\n",
    "# (title[:5], content[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Magezter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import BertTokenizer, BertModel\n",
    "# from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load pre-trained model & tokenizer\n",
    "# model_name = 'indobenchmark/indobert-base-p2'\n",
    "# tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tokenize 'content' (only token spliting)\n",
    "# content_tokens = []\n",
    "# max_sequence_length = 512\n",
    "\n",
    "# for sentence in df['content']:\n",
    "#     tokens = tokenizer.tokenize(sentence)\n",
    "#     if len(tokens) > max_sequence_length - 2:\n",
    "#         tokens = tokens[:max_sequence_length - 2]\n",
    "#     tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "#     content_tokens.extend(tokens)\n",
    "    \n",
    "# # save content_tokens\n",
    "# with open('content_tokens.txt', 'w') as f:\n",
    "#     for item in content_tokens:\n",
    "#         f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
