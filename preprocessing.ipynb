{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- akan melakukan preprocessing corpus hasil scraping website halodoc menggunakan stopwords indonesia dan stemming dengan sastrawi\n",
    "- untuk fine-tuning model indoBERT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "\n",
    "# load stopwords\n",
    "stop_words = set(stopwords.words('indonesian'))\n",
    "\n",
    "# load stemmer\n",
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9986, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>title_length</th>\n",
       "      <th>content</th>\n",
       "      <th>content_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.halodoc.com/ketahui-segala-hal-men...</td>\n",
       "      <td>Ketahui Segala Hal Mengenai COVID-19</td>\n",
       "      <td>38</td>\n",
       "      <td>“Infeksi COVID-19 adalah salah satu penyakit y...</td>\n",
       "      <td>6532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.halodoc.com/bagaimana-cara-merawat...</td>\n",
       "      <td>Bagaimana Cara Merawat Karies Gigi?</td>\n",
       "      <td>37</td>\n",
       "      <td>“Ada banyak pilihan perawatan medis dan rumaha...</td>\n",
       "      <td>5993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.halodoc.com/cegah-burnout-ini-tand...</td>\n",
       "      <td>Cegah Burnout, Ini Tanda Pekerja Butuh Piknik...</td>\n",
       "      <td>61</td>\n",
       "      <td>“Burnout merupakan kondisi ketika seseorang m...</td>\n",
       "      <td>4982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.halodoc.com/kenalan-dengan-terapi-...</td>\n",
       "      <td>Kenalan dengan Terapi ABA untuk Anak Autis</td>\n",
       "      <td>44</td>\n",
       "      <td>“Salah satu cara untuk mengurangi gejala auti...</td>\n",
       "      <td>4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.halodoc.com/10-herbal-untuk-mereda...</td>\n",
       "      <td>10 Herbal untuk Meredakan Sakit Perut Bagian ...</td>\n",
       "      <td>52</td>\n",
       "      <td>“Ada banyak herbal yang dapat membantu mereda...</td>\n",
       "      <td>3638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.halodoc.com/ketahui-segala-hal-men...   \n",
       "1  https://www.halodoc.com/bagaimana-cara-merawat...   \n",
       "2  https://www.halodoc.com/cegah-burnout-ini-tand...   \n",
       "3  https://www.halodoc.com/kenalan-dengan-terapi-...   \n",
       "4  https://www.halodoc.com/10-herbal-untuk-mereda...   \n",
       "\n",
       "                                               title  title_length  \\\n",
       "0              Ketahui Segala Hal Mengenai COVID-19             38   \n",
       "1               Bagaimana Cara Merawat Karies Gigi?             37   \n",
       "2   Cegah Burnout, Ini Tanda Pekerja Butuh Piknik...            61   \n",
       "3        Kenalan dengan Terapi ABA untuk Anak Autis             44   \n",
       "4   10 Herbal untuk Meredakan Sakit Perut Bagian ...            52   \n",
       "\n",
       "                                             content  content_count  \n",
       "0  “Infeksi COVID-19 adalah salah satu penyakit y...           6532  \n",
       "1  “Ada banyak pilihan perawatan medis dan rumaha...           5993  \n",
       "2   “Burnout merupakan kondisi ketika seseorang m...           4982  \n",
       "3   “Salah satu cara untuk mengurangi gejala auti...           4855  \n",
       "4   “Ada banyak herbal yang dapat membantu mereda...           3638  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv('scraping/halodoc1-1000.csv')\n",
    "print(df.shape)\n",
    "\n",
    "# check dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url              0\n",
       "title            0\n",
       "title_length     0\n",
       "content          0\n",
       "content_count    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>title_length</th>\n",
       "      <th>content</th>\n",
       "      <th>content_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.halodoc.com/ketahui-segala-hal-men...</td>\n",
       "      <td>Ketahui Segala Hal Mengenai COVID-19</td>\n",
       "      <td>5</td>\n",
       "      <td>“Infeksi COVID-19 adalah salah satu penyakit y...</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.halodoc.com/bagaimana-cara-merawat...</td>\n",
       "      <td>Bagaimana Cara Merawat Karies Gigi?</td>\n",
       "      <td>5</td>\n",
       "      <td>“Ada banyak pilihan perawatan medis dan rumaha...</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.halodoc.com/cegah-burnout-ini-tand...</td>\n",
       "      <td>Cegah Burnout, Ini Tanda Pekerja Butuh Piknik...</td>\n",
       "      <td>9</td>\n",
       "      <td>“Burnout merupakan kondisi ketika seseorang m...</td>\n",
       "      <td>689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.halodoc.com/kenalan-dengan-terapi-...</td>\n",
       "      <td>Kenalan dengan Terapi ABA untuk Anak Autis</td>\n",
       "      <td>7</td>\n",
       "      <td>“Salah satu cara untuk mengurangi gejala auti...</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.halodoc.com/10-herbal-untuk-mereda...</td>\n",
       "      <td>10 Herbal untuk Meredakan Sakit Perut Bagian ...</td>\n",
       "      <td>8</td>\n",
       "      <td>“Ada banyak herbal yang dapat membantu mereda...</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.halodoc.com/ketahui-segala-hal-men...   \n",
       "1  https://www.halodoc.com/bagaimana-cara-merawat...   \n",
       "2  https://www.halodoc.com/cegah-burnout-ini-tand...   \n",
       "3  https://www.halodoc.com/kenalan-dengan-terapi-...   \n",
       "4  https://www.halodoc.com/10-herbal-untuk-mereda...   \n",
       "\n",
       "                                               title  title_length  \\\n",
       "0              Ketahui Segala Hal Mengenai COVID-19              5   \n",
       "1               Bagaimana Cara Merawat Karies Gigi?              5   \n",
       "2   Cegah Burnout, Ini Tanda Pekerja Butuh Piknik...             9   \n",
       "3        Kenalan dengan Terapi ABA untuk Anak Autis              7   \n",
       "4   10 Herbal untuk Meredakan Sakit Perut Bagian ...             8   \n",
       "\n",
       "                                             content  content_count  \n",
       "0  “Infeksi COVID-19 adalah salah satu penyakit y...            872  \n",
       "1  “Ada banyak pilihan perawatan medis dan rumaha...            808  \n",
       "2   “Burnout merupakan kondisi ketika seseorang m...            689  \n",
       "3   “Salah satu cara untuk mengurangi gejala auti...            649  \n",
       "4   “Ada banyak herbal yang dapat membantu mereda...            512  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reassign 'title_length' and 'content_length' in df dengan panjang dari 'title' dan 'content' yang baru (word count)\n",
    "df['title_length'] = df['title'].apply(lambda x: len(x.split()))\n",
    "df['content_count'] = df['content'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Ukuran dataset sebelum preprocessing: (9986, 5)\n",
      "Ukuran dataset setelah preprocessing: (9981, 5)\n"
     ]
    }
   ],
   "source": [
    "# check duplicates\n",
    "print(df.duplicated().sum())\n",
    "print(f\"Ukuran dataset sebelum preprocessing: {df.shape}\")\n",
    "\n",
    "# drop duplicates\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f\"Ukuran dataset setelah preprocessing: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save to csv\n",
    "# df.to_csv('halodoc1-1000_preprocessed.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary string in 'content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd\n",
    "# tbd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Removal, Stemming, etc. (probably wont be used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove numbers that are not attached to words\n",
    "# def remove_numbers(text):\n",
    "#     text = re.sub(r'(?<!\\S)\\d+(?!\\S)', '', text)\n",
    "#     return text\n",
    "\n",
    "# df['title'] = df['title'].apply(remove_numbers)\n",
    "# df['content'] = df['content'].apply(remove_numbers)\n",
    "# print('hapus angka beridiri sendiri selesai')\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # remove punctuation\n",
    "# def remove_punctuation(text):\n",
    "#     text = re.sub(r'[^\\w\\s]', '', text)\n",
    "#     return text\n",
    "\n",
    "# df['title'] = df['title'].apply(remove_punctuation)\n",
    "# df['content'] = df['content'].apply(remove_punctuation)\n",
    "# print('hapus tanda baca selesai')\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# # remove numbers\n",
    "# def remove_numbers(text):\n",
    "#     text = re.sub(r'\\d+', '', text)\n",
    "#     return text\n",
    "\n",
    "# df['title'] = df['title'].apply(remove_numbers)\n",
    "# df['content'] = df['content'].apply(remove_numbers)\n",
    "# print('hapus angka selesai')\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# # stopword removal + lowercasing\n",
    "# def remove_stopwords(text):\n",
    "#     text = [word.lower() for word in text.split() if word.lower() not in stop_words]\n",
    "#     return \" \".join(text)\n",
    "\n",
    "# df['title'] = df['title'].apply(remove_stopwords)\n",
    "# df['content'] = df['content'].apply(remove_stopwords)\n",
    "# print('stopword removal dan lowercase selesai')\n",
    "\n",
    "# df.head()\n",
    "\n",
    "# # stemming\n",
    "# def stemming(text):\n",
    "#     text = [stemmer.stem(word) for word in text.split()]\n",
    "#     return \" \".join(text)\n",
    "\n",
    "# df['title'] = df['title'].apply(stemming)\n",
    "# df['content'] = df['content'].apply(stemming)\n",
    "# print('stemming selesai')\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use Sentence-BERT to get sentence embeddings (feature extraction)\n",
    "\n",
    "# # import library\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# # load model SBERT (pretrained)\n",
    "# model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "\n",
    "# # get sentence embeddings\n",
    "# title_embeddings = model.encode(df['title'].values)\n",
    "# content_embeddings = model.encode(df['content'].values)\n",
    "\n",
    "# # check shape\n",
    "# print(title_embeddings.shape)\n",
    "# print(content_embeddings.shape)\n",
    "\n",
    "# # check embeddings\n",
    "# print(title_embeddings)\n",
    "# print(content_embeddings)\n",
    "\n",
    "# # check shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save embeddings\n",
    "# np.save('title_embeddings.npy', title_embeddings)\n",
    "# np.save('content_embeddings.npy', content_embeddings)\n",
    "\n",
    "# # load embeddings\n",
    "# title_embeddings = np.load('title_embeddings.npy')\n",
    "# content_embeddings = np.load('content_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use content and title embeddings as dataset for transfer learning indoBERT (information retrieval)\n",
    "\n",
    "# # create new dataframe\n",
    "# df_new = pd.DataFrame()\n",
    "\n",
    "# # add title and content embeddings to df_new\n",
    "# df_new['title_embeddings'] = title_embeddings.tolist()\n",
    "# df_new['content_embeddings'] = content_embeddings.tolist()\n",
    "\n",
    "# # add title and content to df_new\n",
    "# df_new['title'] = df['title']\n",
    "# df_new['content'] = df['content']\n",
    "\n",
    "# # add title_length and content_length to df_new\n",
    "# df_new['title_length'] = df['title_length']\n",
    "# df_new['content_length'] = df['content_count']\n",
    "\n",
    "# # check df_new\n",
    "# df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fine-tuning indoBERT (information retrieval)\n",
    "\n",
    "# # import library\n",
    "# import torch\n",
    "# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# # check device\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load dataset\n",
    "# title_embeddings = torch.tensor(np.array(df_new['title_embeddings'].values.tolist()))\n",
    "# content_embeddings = torch.tensor(np.array(df_new['content_embeddings'].values.tolist()))\n",
    "# title_length = torch.tensor(df_new['title_length'].values)\n",
    "# content_length = torch.tensor(df_new['content_length'].values)\n",
    "\n",
    "# # create TensorDataset\n",
    "# dataset = TensorDataset(title_embeddings, content_embeddings, title_length, content_length)\n",
    "# dataset.tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create DataLoader\n",
    "# dataloader = DataLoader(dataset, batch_size=32)\n",
    "\n",
    "# # check dataloader\n",
    "# next(iter(dataloader))\n",
    "\n",
    "# # import library for information retrieval\n",
    "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "# from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# # load model\n",
    "# model = BertForSequenceClassification.from_pretrained(\n",
    "#     'indobenchmark/indobert-base-p1',\n",
    "#     num_labels = 2,\n",
    "#     output_attentions = False,\n",
    "#     output_hidden_states = False\n",
    "# )\n",
    "\n",
    "# # check model\n",
    "# model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check model parameters\n",
    "# params = list(model.named_parameters())\n",
    "# print(f'Model BERT memiliki sebanyak {len(params)} parameter yang berbeda.\\n')\n",
    "\n",
    "# print('==== Embedding Layer ====\\n')\n",
    "# for p in params[0:5]:\n",
    "#     print(f'{p[0]} memiliki ukuran {tuple(p[1].size())} dan requires_grad={p[1].requires_grad}')\n",
    "\n",
    "# print('\\n==== First Transformer ====\\n')\n",
    "# for p in params[5:21]: \n",
    "#     print(f'{p[0]} memiliki ukuran {tuple(p[1].size())} dan requires_grad={p[1].requires_grad}')\n",
    "\n",
    "# print('\\n==== Output Layer ====\\n')\n",
    "# for p in params[-4:]:\n",
    "#     print(f'{p[0]} memiliki ukuran {tuple(p[1].size())} dan requires_grad={p[1].requires_grad}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tokenization df to list\n",
    "# title = df['title'].tolist()\n",
    "# content = df['content'].tolist()\n",
    "\n",
    "# (title[:5], content[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Magezter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 229k/229k [00:00<00:00, 4.58MB/s]\n",
      "c:\\Users\\Magezter\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Magezter\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 113kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 2.00/2.00 [00:00<?, ?B/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.53k/1.53k [00:00<00:00, 813kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 498M/498M [01:23<00:00, 5.99MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model & tokenizer\n",
    "model_name = 'indobenchmark/indobert-base-p2'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize 'content'\n",
    "content_tokens = []\n",
    "max_sequence_length = 512\n",
    "\n",
    "for sentence in df['content']:\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    if len(tokens) > max_sequence_length - 2:\n",
    "        tokens = tokens[:max_sequence_length - 2]\n",
    "    tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "    content_tokens.extend(tokens)\n",
    "\n",
    "# save content_tokens\n",
    "with open('content_tokens.txt', 'w') as f:\n",
    "    for item in content_tokens:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
